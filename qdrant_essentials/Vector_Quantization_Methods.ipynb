{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ceb782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berk/finreg-navigator/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe144a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"scalar_collection\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True,  # Move originals to disk\n",
    "    ),\n",
    "    quantization_config=models.ScalarQuantization(\n",
    "        scalar=models.ScalarQuantizationConfig(\n",
    "            type=models.ScalarType.INT8,\n",
    "            quantile=0.99,  # Exclude extreme 1% of values\n",
    "            always_ram=True,  # Keep quantized vectors in RAM\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f15f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary quantization setup  \n",
    "client.create_collection(\n",
    "    collection_name=\"binary_collection\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True,\n",
    "    ),\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(\n",
    "            encoding=models.BinaryQuantizationEncoding.ONE_BIT,\n",
    "            always_ram=True,\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca73b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product quantization setup\n",
    "client.create_collection(\n",
    "    collection_name=\"pq_collection\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1024,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True,\n",
    "    ),\n",
    "    quantization_config=models.ProductQuantization(\n",
    "        product=models.ProductQuantizationConfig(\n",
    "            compression=models.CompressionRatio.X32, #or X4, X8, X16, X32 and X64\n",
    "            always_ram=True,\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162cccbf",
   "metadata": {},
   "source": [
    "Method\tAccuracy\tSpeed\t    Compression\n",
    "Scalar\t0.99\t    up to 2x\t4x\n",
    "Binary\t0.95*\t    up to 40x\t32x\n",
    "Product\t0.7\t        0.5x\t    up to 64x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29665f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.query_points(\n",
    "    collection_name=\"quantized_collection\",\n",
    "    query=[0.12] * 1536,\n",
    "    limit=10,\n",
    "    search_params=models.SearchParams(\n",
    "        hnsw_ef=128,\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,  # Use quantization for initial search\n",
    "            rescore=True,   # Enable original vectors-based rescoring\n",
    "            oversampling=3.0,  # Retrieve 3x candidates for rescoring\n",
    "        ),\n",
    "    ),\n",
    "    with_payload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"docs_search\"\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\n",
    "        \"dense\": models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "        \"colbert\": models.VectorParams(\n",
    "            size=128,\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0)  # Reranking only\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config={\"sparse\": models.SparseVectorParams()}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
